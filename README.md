---
title: AI Voice Detection API
emoji: ğŸ™ï¸
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 8000
pinned: false
license: mit
---

# ğŸ™ï¸ VoiceGuard â€” AI Voice Detection API (v2.0)

**Detect AI-Generated Voices with World-Class Accuracy.**

> A production-grade deepfake audio detection system with a custom training pipeline,
> built for the real world â€” noisy environments, lossy codecs, and multilingual audio.

---

## ğŸŒŸ Features

- **Web UI:** Record or upload audio directly in the browser.
- **REST API:** `/detect` endpoint for developers (Hackathon Compliant).
- **Advanced Model:** Wav2Vec2-based deepfake audio classification.
- **Multilingual:** English, Tamil, Hindi, Telugu, Malayalam.
- **Formats:** WAV, MP3, FLAC.
- **Secure:** API Key authentication.

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VoiceGuard API                         â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI  â”‚â”€â”€â”€â–¶â”‚ Audio Engine â”‚â”€â”€â”€â–¶â”‚  Wav2Vec2     â”‚  â”‚
â”‚  â”‚  Server   â”‚    â”‚ (Librosa)    â”‚    â”‚  Classifier   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                      â”‚           â”‚
â”‚       â–¼                                      â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Web UI  â”‚                        â”‚  JSON Result   â”‚  â”‚
â”‚  â”‚ (Record/ â”‚                        â”‚ HUMAN /        â”‚  â”‚
â”‚  â”‚  Upload) â”‚                        â”‚ AI_GENERATED   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Option 1: Web Interface
Open the app at [https://Pandaisop-voice-detection-api.hf.space/](https://Pandaisop-voice-detection-api.hf.space/) and record or upload audio.

### Option 2: API Usage

```json
POST /detect
Content-Type: application/json
X-API-Key: YOUR_API_KEY

{
  "language": "English",
  "audioFormat": "mp3",
  "audioBase64": "UklGR..."
}
```

**Response:**
```json
{
  "result": "AI_GENERATED",
  "confidence": 0.9743,
  "language": "English"
}
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Backend** | FastAPI + Uvicorn | High-performance async API server |
| **AI Model** | Wav2Vec2 (Transformers) | Self-supervised speech representation |
| **Audio DSP** | Librosa + SoundFile | Audio loading, resampling, normalization |
| **Deployment** | Docker + Hugging Face Spaces | Containerized cloud deployment |
| **Auth** | API Key (X-API-Key header) | Secure endpoint access |

---

## ğŸ§  Custom Training Pipeline

VoiceGuard includes a **research-grade training pipeline** in `trainer/` for building custom detection models optimized for your specific use case.

### Architecture

```
Raw Audio â†’ Data Engine â†’ Augmentation â†’ SSL Backbone â†’ Classifier â†’ HUMAN / AI
                                            â”‚
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚        â”‚        â”‚
                              Wav2Vec2   HuBERT   WavLM
                                   â”‚        â”‚        â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                      Ensemble Fusion
```

### Training Features

| Feature | Details |
|---------|---------|
| **3 SSL Backbones** | Wav2Vec2-XLSR-53 (multilingual), HuBERT-Large, WavLM-Large |
| **Ensemble Modes** | Late Fusion, Learned Fusion, Confidence-Weighted |
| **Pooling** | Attentive Statistics Pooling (ECAPA-TDNN style) |
| **Loss Function** | Focal Loss (handles class imbalance) |
| **Optimizer** | AdamW + Cosine Annealing with Warm Restarts |
| **Regularization** | EMA, Dropout, BatchNorm, Gradient Clipping |
| **Mixed Precision** | FP16 training for 2Ã— speed on GPU |
| **Data Augmentation** | 7 types (see below) |

### 7-Type Augmentation Pipeline

| Augmentation | Purpose |
|---|---|
| **Additive Noise** (Gaussian, SNR-controlled) | Robustness to noisy recordings |
| **Speed Perturbation** (0.9Ã—â€“1.1Ã—) | Handle varied speech rates |
| **Pitch Shift** (Â±2 semitones) | Speaker variability |
| **SpecAugment** (time/freq masking) | Regularization (proven in ASR research) |
| **Codec Simulation** (MP3/OGG encode-decode) | Handle lossy compression artifacts |
| **Volume Perturbation** (Â±6 dB) | Microphone gain variability |
| **RIR Convolution** (room impulse response) | Simulate different room acoustics |

### Evaluation Metrics

| Metric | Description |
|--------|-------------|
| **EER** (Equal Error Rate) | Standard for spoofing detection (ASVspoof) |
| **AUC-ROC** | Threshold-independent classification quality |
| **ECE** (Expected Calibration Error) | Is 80% confidence really 80% accurate? |
| **Per-Language Breakdown** | No language left behind |
| **Latency Benchmark** | Inference speed per sample |

### Training Workflow

```bash
cd trainer/

# 1. Add samples to data/human/ and data/ai/
# 2. Validate, analyze, and split
python prepare_data.py

# 3. Train (GPU recommended)
python train.py --config config.yaml

# 4. Evaluate
python evaluate_model.py

# 5. Export & auto-deploy
python export_model.py --integrate
```

### Export Formats
- **HuggingFace Hub** â€” Push directly to your model repository
- **ONNX** â€” Optimized CPU inference with optional quantization
- **TorchScript** â€” Portable PyTorch format
- **Auto-Integration** â€” One command to update the running API

---

## ğŸ“ Project Structure

```
voice-detection-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI server + /detect endpoint
â”‚   â”œâ”€â”€ config.py             # Model & API configuration
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ audio.py          # Audio preprocessing pipeline
â”‚   â”‚   â””â”€â”€ model.py          # VoiceDetector (inference engine)
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ index.html        # Web UI
â”œâ”€â”€ trainer/                  # ğŸ§  Custom Model Training Pipeline
â”‚   â”œâ”€â”€ config.yaml           # All hyperparameters (single source of truth)
â”‚   â”œâ”€â”€ prepare_data.py       # Data validation, SNR analysis, stratified splits
â”‚   â”œâ”€â”€ augment.py            # 7-type augmentation pipeline
â”‚   â”œâ”€â”€ train.py              # Training engine (Focal Loss, EMA, FP16)
â”‚   â”œâ”€â”€ evaluate_model.py     # EER, AUC-ROC, calibration, per-language
â”‚   â”œâ”€â”€ export_model.py       # Export to HF Hub / ONNX / TorchScript
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ backbone.py       # SSL model loaders (Wav2Vec2, HuBERT, WavLM)
â”‚   â”‚   â”œâ”€â”€ classifier.py     # Attentive Stats Pooling + MLP head
â”‚   â”‚   â””â”€â”€ ensemble.py       # 3 ensemble fusion strategies
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ human/            # Real voice samples
â”‚       â””â”€â”€ ai/               # AI-generated samples
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Local Development

```bash
pip install -r requirements.txt
python -m uvicorn app.main:app --reload
```

---

## ğŸ‘¥ Team

Built for hackathon by **Vineet Shukla** & **Yashraj Rastogi**.

## ğŸ“„ License

MIT License
